{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "based-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Python Packages. \n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import unicodedata\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "brazilian-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_common_words_from_wiki_page(n: int, page_id: int)->dict:\n",
    "    \"\"\"\n",
    "    The function takes a page id of wiki and return the n top words with title. \n",
    "    \n",
    "    Input Parms:\n",
    "    n (int): number of top words.\n",
    "    page_id (int): page id. \n",
    "    \n",
    "    Returns:\n",
    "    web_scrapped_list (dict): the dict containing all top n word count and Title.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Building the URL. \n",
    "    URL = f\"https://en.wikipedia.org/w/api.php?action=query&prop=extracts&pageids={page_id}&explaintext&format=json\"\n",
    "    raw_text = requests.get(URL).text\n",
    "    \n",
    "    # Getting the title of the page. \n",
    "    string_to_json = json.loads(raw_text)\n",
    "    title_of_wiki_page = string_to_json['query']['pages']['21721040']['title']\n",
    "    \n",
    "    # preprocessing of the raw text. \n",
    "    # step1: Removing the URLs if present.\n",
    "    processed_text = re.sub(r'https?://\\S+|www\\.\\S+', '', raw_text)\n",
    "    \n",
    "    # step2: Removing the acceted characters. \n",
    "    processed_text = unicodedata.normalize('NFKD', processed_text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    # step3: Removing the punctutation from the string.\n",
    "    processed_text = re.sub(r'[^a-zA-Z0-9]', ' ', processed_text)\n",
    "    \n",
    "    # step4: Removing the numbers and special characters.\n",
    "    processed_text = re.sub(r'[^a-zA-Z]', ' ', processed_text)\n",
    "    \n",
    "    # step5: Removing the white space from the string. \n",
    "    processed_text = re.sub(r'^\\s*|\\s\\s*', ' ', processed_text).strip()\n",
    "    \n",
    "    # step6: Removing the stop words.\n",
    "    stp_words = stopwords.words(\"english\")\n",
    "    pattern = re.compile(r'\\b(' + r'|'.join(stp_words) + r')\\b\\s*')\n",
    "    processed_text = pattern.sub('', processed_text)\n",
    "    \n",
    "    # step7: Removing single letters.\n",
    "    processed_text = re.sub('(\\\\b[A-Za-z] \\\\b|\\\\b [A-Za-z]\\\\b)', '', processed_text)\n",
    "    \n",
    "    # split() returns list of all the words in the string\n",
    "    word_split = processed_text.split()\n",
    "\n",
    "    # Pass the split_it list to instance of Counter class.\n",
    "    count_of_words = Counter(word_split)\n",
    "\n",
    "    # most_common() produces l frequently encountered\n",
    "    most_occur = Counters_found.most_common(n)\n",
    "    \n",
    "    # dict to hold the results.\n",
    "    final_output = defaultdict(list)\n",
    "    for word in most_occur:\n",
    "        final_output[word[1]].append(word[0])\n",
    "    final_output = dict(final_output)\n",
    "    final_output['Title'] = title_of_wiki_page\n",
    "    \n",
    "    # returning the final dict.\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "artistic-satellite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{19: ['questions'], 17: ['Overflow'], 16: ['Stack'], 11: ['users'], 10: ['question'], 8: ['answer', 'site'], 7: ['website', 'answers'], 6: ['The'], 'Title': 'Stack Overflow'}\n"
     ]
    }
   ],
   "source": [
    "# Function call and printing the results. \n",
    "final_dict = find_common_words_from_wiki_page(10, 21721040)\n",
    "print(final_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
